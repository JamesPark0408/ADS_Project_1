{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d1048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:52:45.698482Z",
     "start_time": "2022-08-21T21:52:45.695659Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO TAKE NOTE SOME AGGREGATION IS DONE DURING MODELING \n",
    "#  AS SOME DATA IS NEEDED FOR VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72e490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:52:46.236049Z",
     "start_time": "2022-08-21T21:52:45.701034Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9893bf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:04.949902Z",
     "start_time": "2022-08-21T21:52:46.238063Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60cbfad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.173748Z",
     "start_time": "2022-08-21T21:53:04.951914Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf_green = spark.read.parquet('../data/raw/green_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3b3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.176147Z",
     "start_time": "2022-08-21T21:52:45.699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initial data amount\n",
    "sdf_green.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc7a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.177237Z",
     "start_time": "2022-08-21T21:52:45.701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f8c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.178631Z",
     "start_time": "2022-08-21T21:52:45.702Z"
    }
   },
   "outputs": [],
   "source": [
    "sdf_green.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317eb37e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.180146Z",
     "start_time": "2022-08-21T21:52:45.705Z"
    }
   },
   "outputs": [],
   "source": [
    "sdf_green_pre = sdf_green.withColumn('shift', F.hour(F.col('lpep_pickup_datetime')))\n",
    "sdf_green_pre.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9a541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.181641Z",
     "start_time": "2022-08-21T21:52:45.706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the datetime to days(Mon,Tue,...,Sun) \n",
    "# 1 - Sunday, 2-Monday, ..., 7-Saturday\n",
    "sdf_green_pre = sdf_green.withColumn('shift', \n",
    "                                        F.when(\n",
    "                                            (F.hour(F.col('lpep_pickup_datetime')) > 3)\n",
    "                                            & (F.hour(F.col('lpep_pickup_datetime')) < 18),\n",
    "                                            'Morning'\n",
    "                                        ).otherwise('Night')\n",
    "                                    )\n",
    "sdf_green_pre = sdf_green_pre.withColumn('day', F.date_format(F.col('lpep_pickup_datetime'), \"E\"))\n",
    "sdf_green_pre2 = sdf_green_pre.withColumn('fare', F.round(F.col('total_amount')-F.col('tip_amount'),2))\n",
    "sdf_green_pre3 = sdf_green_pre2.where(\n",
    "                                    (F.col('fare')>2.5)\n",
    "                                    & (F.col('passenger_count')>0)\n",
    "                                    & (F.col('passenger_count')<7)\n",
    "                                    & (F.col('trip_distance')>0)\n",
    "                                    & (F.col('PULocationID')<=263)\n",
    "                                    & (F.col('PULocationID')>1) # Don't include EWR as not in Green taxi zone as indicated in user guide (show picture)\n",
    "                                     )\n",
    "sdf_green_pre3 = sdf_green_pre3.withColumn('Date',F.to_date('lpep_pickup_datetime'))\n",
    "sdf_green_pre4 = sdf_green_pre3.filter(F.col('Date') >= '2021-07-01')\n",
    "sdf_green_pre4 = sdf_green_pre4.filter(F.col('Date') < '2022-05-01')\n",
    "sdf_green_pre4.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92eb9ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.182920Z",
     "start_time": "2022-08-21T21:52:45.708Z"
    }
   },
   "outputs": [],
   "source": [
    "# As we disregarded the tip amount as it is not accounted for in cash tips\n",
    "# we will only account for total amount - tip and we can remove the rest that is attributed to the total amount and payment type would not matter\n",
    "# VendorID will not be of importance as we are looking at green taxis in general\n",
    "rel_col = ('lpep_pickup_datetime', 'lpep_dropoff_datetime', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'fare', 'trip_type', 'shift', 'Date', 'Day')\n",
    "sdf_green_pre5 = sdf_green_pre4.select(*rel_col)\n",
    "sdf_green_pre5.limit(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cc08a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.184358Z",
     "start_time": "2022-08-21T21:52:45.709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we import the weather dataset to be added\n",
    "weather = spark.read.option(\"header\",True).csv(\"../data/raw/Weather.csv\")\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e0aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.185713Z",
     "start_time": "2022-08-21T21:52:45.710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only want the 3 stations near New York City\n",
    "rel_cols = ('NAME', 'DATE', 'TAVG')\n",
    "weather_NYC = weather.select(*rel_cols).filter((F.col('NAME') == 'JFK INTERNATIONAL AIRPORT, NY US')\n",
    "                                               |(F.col('NAME') == 'NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US')\n",
    "                                               |(F.col('NAME') == 'NY CITY CENTRAL PARK, NY US')\n",
    "                                              )\n",
    "\n",
    "weather_NYC.filter(F.col('NAME') == 'NY CITY CENTRAL PARK, NY US').limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ded4f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.186823Z",
     "start_time": "2022-08-21T21:52:45.711Z"
    }
   },
   "outputs": [],
   "source": [
    "# As NYC Central Park does not have data for temperature, we will use Newark and JFK instead\n",
    "# Using the appropriated percentage according to weatherspark, we will split the weightage of 58% of central park accordingly to Newark and JFK (2:1 ratio)\n",
    "# So Newark is 67% while JFK contributes 33%\n",
    "rel_cols = ('NAME', 'DATE', 'TAVG')\n",
    "weather_NYC = weather.select(*rel_cols).filter((F.col('NAME') == 'JFK INTERNATIONAL AIRPORT, NY US')\n",
    "                                               |(F.col('NAME') == 'NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US')\n",
    "                                              )\n",
    "weather_NYC = weather_NYC.withColumn('WTAVG', F.when((F.col('NAME') == 'NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US'),\n",
    "                                                        (F.col('TAVG')*2/3).cast('int')\n",
    "                                                    ).otherwise((F.col('TAVG')/3)).cast('int')\n",
    "                                    )\n",
    "weather_NYC = weather_NYC.withColumn('Date', F.to_date('DATE'))\n",
    "weather_NYC.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867ed75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.187913Z",
     "start_time": "2022-08-21T21:52:45.712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we aggregate the weighted average together\n",
    "cols = ('Date', 'WTAVG')\n",
    "weather_NYC_cur = weather_NYC.select(*cols)\n",
    "agg_NYC_weather = weather_NYC_cur.groupby('Date') \\\n",
    "                                 .agg(\n",
    "                                    F.sum('WTAVG').alias('temp')\n",
    "                                  )\n",
    "agg_NYC_weather.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c056151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.189296Z",
     "start_time": "2022-08-21T21:52:45.714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we want to add the temperature accordingly to the dates in the main dataframe\n",
    "\n",
    "merged_sdf = sdf_green_pre5.join(agg_NYC_weather, on='Date', how='left')\n",
    "merged_sdf.orderBy('Date').limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef8bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T21:53:05.191067Z",
     "start_time": "2022-08-21T21:52:45.715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output the merged dataframe to data folder in parquet\n",
    "merged_sdf.write.mode('overwrite').parquet('../data/curated/result')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
